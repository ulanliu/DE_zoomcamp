{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae4252e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9a94e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True),\n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True),\n",
    "    types.StructField('dropoff_datetime', types.TimestampType(), True),\n",
    "    types.StructField('PULocationID', types.IntegerType(), True),\n",
    "    types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "    types.StructField('SR_Flag', types.StringType(), True),\n",
    "    types.StructField('Affiliated_base_number', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0e0106",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv('fhv_tripdata_2021-06.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73deae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d577bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.parquet('fhv/2021/06/', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef562e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/13 14:42:14 WARN Utils: Your hostname, liujunweideMacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.0.18 instead (on interface en0)\n",
      "23/03/13 14:42:14 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/13 14:42:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.parquet('fhv/2021/06')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8c5af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29ddd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f178251",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "452470"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(F.dayofmonth(df.pickup_datetime) == '15').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645fd7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('duration', F.datediff(df.dropoff_datetime, df.pickup_datetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cb46f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('duration', (F.unix_timestamp(df.dropoff_datetime) - F.unix_timestamp(df.pickup_datetime))/3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2001427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:======================================>                   (8 + 4) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+----------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|        duration|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+----------------+\n",
      "|              B02872|2021-06-25 13:55:41|2021-06-28 08:48:25|          98|         265|      N|                B02872|66.8788888888889|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.sort(df.duration.desc()).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a119c24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zone = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('taxi+_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbcee64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------+------------+\n",
      "|LocationID|Borough|          Zone|service_zone|\n",
      "+----------+-------+--------------+------------+\n",
      "|         1|    EWR|Newark Airport|         EWR|\n",
      "|         2| Queens|   Jamaica Bay|   Boro Zone|\n",
      "+----------+-------+--------------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zone.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b915076",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df.join(df_zone, df.PULocationID == df_zone.LocationID).drop(df_zone.LocationID)\n",
    "df_join = df_join.withColumnRenamed('Borough', 'pickup_borough') \\\n",
    "    .withColumnRenamed('Zone', 'pickup_zone') \\\n",
    "    .withColumnRenamed('service_zone', 'pickup_service_zone')\n",
    "df_join = df_join.join(df_zone, df.DOLocationID == df_zone.LocationID).drop(df_zone.LocationID)\n",
    "df_join = df_join.withColumnRenamed('Borough', 'dropoff_borough') \\\n",
    "    .withColumnRenamed('Zone', 'dropoff_zone') \\\n",
    "    .withColumnRenamed('service_zone', 'dropoff_service_zone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d6a3482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-------------------+--------------+-------------------+-------------------+----------+---------------+--------------------+--------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|           duration|pickup_borough|        pickup_zone|pickup_service_zone|LocationID|dropoff_borough|        dropoff_zone|dropoff_service_zone|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-------------------+--------------+-------------------+-------------------+----------+---------------+--------------------+--------------------+\n",
      "|              B02875|2021-06-02 13:50:06|2021-06-02 13:59:21|         223|         129|      N|                B02875|0.15416666666666667|        Queens|           Steinway|          Boro Zone|       129|         Queens|     Jackson Heights|           Boro Zone|\n",
      "|              B02864|2021-06-04 18:27:04|2021-06-04 18:54:29|          61|         256|      N|                B02864|0.45694444444444443|      Brooklyn|Crown Heights North|          Boro Zone|       256|       Brooklyn|Williamsburg (Sou...|           Boro Zone|\n",
      "|              B02510|2021-06-02 15:23:37|2021-06-02 15:46:57|          21|          89|      N|                  null| 0.3888888888888889|      Brooklyn|   Bensonhurst East|          Boro Zone|        89|       Brooklyn|Flatbush/Ditmas Park|           Boro Zone|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+-------------------+--------------+-------------------+-------------------+----------+---------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eee5baf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peter/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_join.registerTempTable('fhv_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fcb388f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:======================================>                  (8 + 4) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+\n",
      "|        pickup_zone|amonut|\n",
      "+-------------------+------+\n",
      "|Crown Heights North|231279|\n",
      "|       East Village|221244|\n",
      "|        JFK Airport|188867|\n",
      "+-------------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT pickup_zone, COUNT(*) as amonut\n",
    "    FROM fhv_data\n",
    "    GROUP BY 1\n",
    "    ORDER BY 2 DESC\n",
    "    LIMIT 3\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad0db1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
